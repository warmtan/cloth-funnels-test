{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import random\n",
    "import math\n",
    "import scipy.io\n",
    "import k3d\n",
    "import pickle as pkl\n",
    "import matplotlib.pyplot as plt\n",
    "import trimesh\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "import pathlib\n",
    "import json\n",
    "import pickle as pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def readOBJ(file):\n",
    "\tV, Vt, F, Ft = [], [], [], []\n",
    "\twith open(file, 'r') as f:\n",
    "\t\tT = f.readlines()\n",
    "\tfor t in T:\n",
    "\t\t# 3D vertex\n",
    "\t\tif t.startswith('v '):\n",
    "\t\t\tv = [float(n) for n in t.replace('v ','').split(' ')]\n",
    "\t\t\tV += [v]\n",
    "\t\t# UV vertex\n",
    "\t\telif t.startswith('vt '):\n",
    "\t\t\tv = [float(n) for n in t.replace('vt ','').split(' ')]\n",
    "\t\t\tVt += [v]\n",
    "\t\t# Face\n",
    "\t\telif t.startswith('f '):\n",
    "\t\t\tidx = [n.split('/') for n in t.replace('f ','').split(' ')]\n",
    "\t\t\tf = [int(n[0]) - 1 for n in idx]\n",
    "\t\t\tF += [f]\n",
    "\t\t\t# UV face\n",
    "\t\t\tif '/' in t:\n",
    "\t\t\t\tf = [int(n[1]) - 1 for n in idx]\n",
    "\t\t\t\tFt += [f]\n",
    "\tV = np.array(V, np.float32)\n",
    "\tVt = np.array(Vt, np.float32)\n",
    "\tF = np.array(F)\n",
    "\tif Ft: assert len(F) == len(Ft), 'Inconsistent .obj file, mesh and UV map do not have the same number of faces' \n",
    "\telse: Vt, Ft = None, None\n",
    "\treturn V, F, Vt, Ft\n",
    "\n",
    "def rotation_matrix(axis, theta):\n",
    "    \"\"\"\n",
    "    Return the rotation matrix associated with counterclockwise rotation about\n",
    "    the given axis by theta radians.\n",
    "    \"\"\"\n",
    "    axis = np.asarray(axis)\n",
    "    axis = axis / math.sqrt(np.dot(axis, axis))\n",
    "    a = math.cos(theta / 2.0)\n",
    "    b, c, d = -axis * math.sin(theta / 2.0)\n",
    "    aa, bb, cc, dd = a * a, b * b, c * c, d * d\n",
    "    bc, ad, ac, ab, bd, cd = b * c, a * d, a * c, a * b, b * d, c * d\n",
    "    return np.array([[aa + bb - cc - dd, 2 * (bc + ad), 2 * (bd - ac)],\n",
    "                     [2 * (bc - ad), aa + cc - bb - dd, 2 * (cd + ab)],\n",
    "                     [2 * (bd + ac), 2 * (cd - ab), aa + dd - bb - cc]])\n",
    "\n",
    "def rgb_to_hex(rgb):\n",
    "    if rgb.dtype == np.uint8:\n",
    "        pass\n",
    "    elif rgb.dtype in (np.float16, np.float32, np.float64):\n",
    "        # print('Assuming Value in [0.0, 1.0]')\n",
    "        rgb = (rgb * 255).astype(np.uint8)\n",
    "    assert(rgb.dtype == np.uint8)\n",
    "    hex = np.sum(rgb.astype(np.uint32) * np.array([1, 256, 256 ** 2])[::-1], axis=-1)\n",
    "    return hex\n",
    "\n",
    "def get_cloth_img(V, axes=(0, 2)):\n",
    "\tranges = [[-1, 1], [-1, 1], [-1, 1]]\n",
    "\timg_shape = [256, 256]\n",
    "\txy_img = np.zeros(img_shape)\n",
    "\t\t\t\n",
    "\txy = V[:, axes,].copy()\n",
    "\t#center xy coordinates\n",
    "\txy[:, 0] = xy[:, 0] - (np.max(xy[:, 0]) + np.min(xy[:, 0])) / 2\n",
    "\txy[:, 1] = xy[:, 1] - (np.max(xy[:, 1]) + np.min(xy[:, 1])) / 2\n",
    "\n",
    "\tfor i in range(len(xy)):\n",
    "\t\tcanonical_coord = xy[i]\n",
    "\t\timage_coord = np.array([((canonical_coord[i] - ranges[i][0])/(ranges[i][1] - ranges[i][0]))*img_shape[i] for i in range(2)])\n",
    "\t\txy_img[int(image_coord[0]), int(image_coord[1])] = 1\n",
    "\t\n",
    "\treturn xy_img\n",
    "\n",
    "def visualize_vertices(img, instance=None):\n",
    "        plt.imshow(img)\n",
    "        current_values = plt.gca().get_yticks()\n",
    "        plt.gca().set_yticklabels([f'{((x-128)/128):.2f}'for x in current_values])\n",
    "        plt.gca().set_xticklabels([f'{((x-128)/128):.2f}'for x in current_values])\n",
    "        if instance is not None:\n",
    "            plt.title(f'{instance}')\n",
    "        plt.show()\n",
    "\n",
    "def is_shirt(V, F, threshold=180):\n",
    "    last_F = F.copy()[:,-1].reshape(-1, 1)\n",
    "    until_last_F = F.copy()[:, :-1]\n",
    "\n",
    "    G = nx.Graph()\n",
    "    nodes = np.arange(V.shape[0])\n",
    "    G.add_nodes_from(nodes)\n",
    "    edges = np.array([F, np.concatenate([last_F, until_last_F], 1)]).reshape(2, -1).transpose(1, 0)\n",
    "    G.add_edges_from(edges)\n",
    "\n",
    "    N = 0\n",
    "    for i in range(len(G.nodes)):\n",
    "        n = len(list(nx.all_neighbors(G, i)))\n",
    "        if n >= 4:\n",
    "            G.remove_node(i)\n",
    "            # if(n < 4):\n",
    "    connected_components = list(nx.connected_components(G))\n",
    "\n",
    "    component_lengths = []\n",
    "    for c in connected_components:\n",
    "        component_lengths.append(len(c))\n",
    "    max_component_length = max(component_lengths)\n",
    "    \n",
    "    if(max_component_length < threshold):\n",
    "        return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "NUM_DIRS=10000\n",
    "\n",
    "def get_all_data(input_path, save_path, num_dirs=10, mode='visualize'):\n",
    "    os.chdir(input_path)\n",
    "    dirs = os.listdir()\n",
    "    random.shuffle(dirs)\n",
    "    counter = 0\n",
    "    stats = {\n",
    "        'width':[],\n",
    "        'height':[],\n",
    "        'instance':[],\n",
    "        'area':[],\n",
    "    }\n",
    "    print(f\"{len(dirs)} directories found\")\n",
    "    for i, dir_idx in tqdm(zip(range(num_dirs), dirs)):\n",
    "\n",
    "        dir_path = os.path.join(train_path, dir_idx)\n",
    "        os.chdir(dir_path)\n",
    "        \n",
    "        # print(glob.glob(\"*.obj\"))\n",
    "        zrot = scipy.io.loadmat(glob.glob(\"*.mat\")[0])[\"zrot\"][0][0]\n",
    "        instances = glob.glob(\"*.obj\")\n",
    "        for i, instance in enumerate(instances):\n",
    "\n",
    "            cloth_category = instance.split('.')[0]\n",
    "\n",
    "            full_path = os.path.join(dir_path, instance)\n",
    "            V, F, Vt, Ft = readOBJ(full_path)\n",
    "\n",
    "            rot_matrix = rotation_matrix([0, 0, 1], zrot)\n",
    "            V = V @ rot_matrix\n",
    "\n",
    "            max_height = np.max(V[:, 2])\n",
    "            min_height = np.min(V[:, 2])\n",
    "            height = max_height - min_height\n",
    "\n",
    "            max_width = np.max(V[:, 0])\n",
    "            min_width = np.min(V[:, 0])\n",
    "            width = max_width - min_width\n",
    "\n",
    "            # print(\"Height\", height, \"Width\", width, \"Depth\", V[:, 1])\n",
    "            max_diffs = np.max(V, axis=0) - np.min(V, axis=0)\n",
    "            width = max_diffs[0]\n",
    "            height = max_diffs[2]\n",
    "            area = height * width\n",
    "            # print(np.max(V, axis=0) - np.min(V, axis=0))\n",
    "            w2h = max_diffs[0]/max_diffs[2]\n",
    "            # print(\"width to height\", w2h)\n",
    "            cloth_img = get_cloth_img(V)\n",
    "\n",
    "            if mode == 'visualize':\n",
    "                visualize_vertices(cloth_img, instance)\n",
    "            \n",
    "\n",
    "            stats['height'].append(height)\n",
    "            stats['width'].append(width)\n",
    "            stats['instance'].append(instance)\n",
    "            stats['area'].append(area)\n",
    "            \n",
    "            diffs = []\n",
    "            mins = []\n",
    "            for i in range(3):\n",
    "                dim_max = np.max(V[:, i])\n",
    "                dim_min = np.min(V[:, i])\n",
    "                mins.append(dim_min)\n",
    "                diffs.append(dim_max - dim_min)\n",
    "\n",
    "            diffs = np.array(diffs)\n",
    "            mins = np.array(mins)\n",
    "\n",
    "            NOCS = (V.copy() - mins)/diffs\n",
    "\n",
    "            instance_id = dir_idx + '_' + instance\n",
    "\n",
    "            data = {\n",
    "                'verts':V, \n",
    "                'nocs':NOCS,\n",
    "                'faces':F,\n",
    "                'height':height,\n",
    "                'width':width,\n",
    "                'cloth_img':cloth_img,\n",
    "                'instance':instance,\n",
    "                'id':instance_id,\n",
    "            }\n",
    "\n",
    "            category_path = out_path + '/' + cloth_category\n",
    "            if mode == 'save':\n",
    "                pathlib.Path(category_path).mkdir(exist_ok=True, parents=True)\n",
    "                path = os.path.join(category_path, instance_id + '.pkl')\n",
    "                with open(path, 'wb') as handle:\n",
    "                    pkl.dump(data, handle)\n",
    "\n",
    "        # df = pd.DataFrame.from_dict(stats)\n",
    "\n",
    "train_path = \"/local/crv/dataset/CLOTH3D/CLOTH3D/train/\"\n",
    "out_path = '/local/crv/acanberk/folding-unfolding/src/cloth_data/cloth3d_pickle'\n",
    "# get_all_data(train_path, out_path, num_dirs=4000, mode='save')\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def size_filter_fn(data):\n",
    "    MIN_HEIGHT = 0.6\n",
    "    MAX_HEIGHT = 0.9\n",
    "    height_constraint = (data['height'] < MAX_HEIGHT) and (data['height'] > MIN_HEIGHT)\n",
    "    return height_constraint\n",
    "\n",
    "def shirt_filter_fn(data):\n",
    "   \n",
    "    width_to_height = data['width']/data['height']\n",
    "    width_to_height_constraint = width_to_height > 1.5\n",
    "    \n",
    "    is_shirt_not_jacket = is_shirt(data['verts'], data['faces'])\n",
    "\n",
    "    return size_filter_fn(data) and width_to_height_constraint and is_shirt_not_jacket\n",
    "    \n",
    "\n",
    "def filter_clothes(in_path, out_path, filter_fn, train_test_split=0.7, confirm=False, save=False):\n",
    "\n",
    "    images = []\n",
    "    save_files = []\n",
    "\n",
    "    files = os.listdir(in_path)\n",
    "    for i, file in zip(range(4000), files):\n",
    "\n",
    "        with open(os.path.join(in_path, file), 'rb') as handle:\n",
    "            data = pkl.load(handle)\n",
    "            if filter_fn(data):\n",
    "               \n",
    "                #vertical videw\n",
    "                # plt.imshow(get_cloth_img(data['verts'], axes=(0, 1)))\n",
    "                # plt.show()\n",
    "               \n",
    "                if confirm:\n",
    "                    plt.imshow(data['cloth_img'])\n",
    "                    plt.show()\n",
    "                    r = input(\"Accept? (X if bad, E if escape)\")\n",
    "                    if r.lower() == 'e':\n",
    "                        break\n",
    "                    if r.lower() == 'x':\n",
    "                        print(\"bad\")\n",
    "                    else:\n",
    "                        print(\"good\")\n",
    "                        images.append(data['cloth_img'])\n",
    "                        save_files.append(file)\n",
    "                else:\n",
    "                    images.append(data['cloth_img'])\n",
    "                    save_files.append(file)\n",
    "                    \n",
    "                train_test_split_mark = int(len(save_files) * train_test_split)\n",
    "                save_files_dict = {\n",
    "                    'train':save_files[:train_test_split_mark],\n",
    "                    'test':save_files[train_test_split_mark:]\n",
    "                }\n",
    "                #save json\n",
    "                if save:\n",
    "                    with open(os.path.join(out_path), 'w') as handle:\n",
    "                        json.dump(save_files_dict, handle)\n",
    "                \n",
    "                print(\"Chosen\", len(save_files), \"cloth instances\")\n",
    "\n",
    "        if len(images) == 25:\n",
    "            fig, axes = plt.subplots(5, 5, figsize=(10, 10))\n",
    "            for i, ax in zip(range(len(images)), axes.flatten()):\n",
    "                ax.imshow(images[i])\n",
    "                ax.set_axis_off()\n",
    "            fig.tight_layout()\n",
    "            plt.show()\n",
    "            images = []\n",
    "\n",
    "shirt_path = '/local/crv/acanberk/folding-unfolding/src/cloth_data/cloth3d_pickle/Trousers'\n",
    "out_path = '/local/crv/acanberk/folding-unfolding/src/cloth_data/cloth3d_pickle/pants.json'\n",
    "filter_clothes(shirt_path, out_path, size_filter_fn, confirm=False, save=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_path = '/local/crv/acanberk/folding-unfolding/src/cloth_data/cloth3d_pickle/Tshirt'\n",
    "out_path = '/local/crv/acanberk/folding-unfolding/src/cloth_data/cloth3d_pickle/longsleeve.json'\n",
    "\n",
    "#read out path\n",
    "with open(out_path, 'r') as handle:\n",
    "    save_files_dict = json.load(handle)\n",
    "\n",
    "train = save_files_dict['train']\n",
    "test = save_files_dict['test']\n",
    "\n",
    "images = []\n",
    "for file in test:\n",
    "    with open(os.path.join(in_path, file), 'rb') as handle:\n",
    "        data = pkl.load(handle)\n",
    "        images.append(data['cloth_img'])\n",
    "        # plt.imshow(data['cloth_img'])\n",
    "        # plt.show()\n",
    "images_array = np.array(images)\n",
    "plt.imshow(images_array.mean(axis=0))"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
